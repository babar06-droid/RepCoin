{"dependencies":[{"name":"@tensorflow/tfjs-core","data":{"asyncType":null,"isESMImport":true,"locs":[{"start":{"line":18,"column":0,"index":706},"end":{"line":18,"column":44,"index":750}}],"key":"qIleUpSDMUXFynEGc51k60/pDSs=","exportNames":["*"],"imports":1}},{"name":"seedrandom","data":{"asyncType":null,"isESMImport":true,"locs":[{"start":{"line":19,"column":0,"index":751},"end":{"line":19,"column":41,"index":792}}],"key":"QSFFm6arjkkk5s1ZGE1gSL7+aSE=","exportNames":["*"],"imports":1}},{"name":"./iterators/lazy_iterator","data":{"asyncType":null,"isESMImport":true,"locs":[{"start":{"line":20,"column":0,"index":793},"end":{"line":20,"column":147,"index":940}}],"key":"30QjIozoXZtH47rEd8+EVa8kbIU=","exportNames":["*"],"imports":1}},{"name":"./util/deep_map","data":{"asyncType":null,"isESMImport":true,"locs":[{"start":{"line":21,"column":0,"index":941},"end":{"line":21,"column":79,"index":1020}}],"key":"IVCmPru+35fCMZbVSfz5R+EE1wg=","exportNames":["*"],"imports":1}}],"output":[{"data":{"code":"__d(function (global, require, _$$_IMPORT_DEFAULT, _$$_IMPORT_ALL, module, exports, _dependencyMap) {\n  \"use strict\";\n\n  Object.defineProperty(exports, '__esModule', {\n    value: true\n  });\n  function _interopNamespace(e) {\n    if (e && e.__esModule) return e;\n    var n = {};\n    if (e) Object.keys(e).forEach(function (k) {\n      var d = Object.getOwnPropertyDescriptor(e, k);\n      Object.defineProperty(n, k, d.get ? d : {\n        enumerable: true,\n        get: function () {\n          return e[k];\n        }\n      });\n    });\n    n.default = e;\n    return n;\n  }\n  Object.defineProperty(exports, \"Dataset\", {\n    enumerable: true,\n    get: function () {\n      return Dataset;\n    }\n  });\n  exports.datasetFromIteratorFn = datasetFromIteratorFn;\n  exports.array = array;\n  exports.zip = zip;\n  var _tensorflowTfjsCore = require(_dependencyMap[0], \"@tensorflow/tfjs-core\");\n  var tf = _interopNamespace(_tensorflowTfjsCore);\n  var _seedrandom = require(_dependencyMap[1], \"seedrandom\");\n  var seedrandom = _interopNamespace(_seedrandom);\n  var _iteratorsLazy_iterator = require(_dependencyMap[2], \"./iterators/lazy_iterator\");\n  var _utilDeep_map = require(_dependencyMap[3], \"./util/deep_map\");\n  /**\n   * @license\n   * Copyright 2018 Google LLC. All Rights Reserved.\n   * Licensed under the Apache License, Version 2.0 (the \"License\");\n   * you may not use this file except in compliance with the License.\n   * You may obtain a copy of the License at\n   *\n   * http://www.apache.org/licenses/LICENSE-2.0\n   *\n   * Unless required by applicable law or agreed to in writing, software\n   * distributed under the License is distributed on an \"AS IS\" BASIS,\n   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   * See the License for the specific language governing permissions and\n   * limitations under the License.\n   *\n   * =============================================================================\n   */\n\n  // TODO(soergel): consider vectorized operations within the pipeline.\n  /**\n   * Represents a potentially large list of independent data elements (typically\n   * 'samples' or 'examples').\n   *\n   * A 'data example' may be a primitive, an array, a map from string keys to\n   * values, or any nested structure of these.\n   *\n   * A `Dataset` represents an ordered collection of elements, together with a\n   * chain of transformations to be performed on those elements. Each\n   * transformation is a method of `Dataset` that returns another `Dataset`, so\n   * these may be chained, e.g.\n   * `const processedDataset = rawDataset.filter(...).map(...).batch(...)`.\n   *\n   * Data loading and transformation is done in a lazy, streaming fashion.  The\n   * dataset may be iterated over multiple times; each iteration starts the data\n   * loading anew and recapitulates the transformations.\n   *\n   * A `Dataset` is typically processed as a stream of unbatched examples -- i.e.,\n   * its transformations are applied one example at a time. Batching produces a\n   * new `Dataset` where each element is a batch. Batching should usually come\n   * last in a pipeline, because data transformations are easier to express on a\n   * per-example basis than on a per-batch basis.\n   *\n   * The following code examples are calling `await dataset.forEachAsync(...)` to\n   * iterate once over the entire dataset in order to print out the data.\n   *\n   * @doc {heading: 'Data', subheading: 'Classes', namespace: 'data'}\n   */\n  class Dataset {\n    constructor() {\n      this.size = null;\n    }\n    // TODO(soergel): Make Datasets report whether repeated iterator() calls\n    // produce the same result (e.g., reading from a file) or different results\n    // (e.g., from the webcam).  Currently we don't make this distinction but it\n    // could be important for the user to know.\n    // abstract isDeterministic(): boolean;\n    /**\n     * Groups elements into batches.\n     *\n     * It is assumed that each of the incoming dataset elements has the same\n     * structure -- i.e. the same set of keys at each location in an object\n     * hierarchy.  For each key, the resulting `Dataset` provides a batched\n     * element collecting all of the incoming values for that key.\n     *\n     *  * Incoming primitives are grouped into a 1-D Tensor.\n     *  * Incoming Tensors are grouped into a new Tensor where the 0th axis is\n     *    the batch dimension.\n     *  * Incoming arrays are converted to Tensor and then batched.\n     *  * A nested array is interpreted as an n-D Tensor, so the batched result\n     *    has n+1 dimensions.\n     *  * An array that cannot be converted to Tensor produces an error.\n     *\n     * If an array should not be batched as a unit, it should first be converted\n     * to an object with integer keys.\n     *\n     * Here are a few examples:\n     *\n     * Batch a dataset of numbers:\n     * ```js\n     * const a = tf.data.array([1, 2, 3, 4, 5, 6, 7, 8]).batch(4);\n     * await a.forEachAsync(e => e.print());\n     * ```\n     *\n     * Batch a dataset of arrays:\n     * ```js\n     * const b = tf.data.array([[1], [2], [3], [4], [5], [6], [7], [8]]).batch(4);\n     * await b.forEachAsync(e => e.print());\n     * ```\n     *\n     * Batch a dataset of objects:\n     * ```js\n     * const c = tf.data.array([{a: 1, b: 11}, {a: 2, b: 12}, {a: 3, b: 13},\n     *   {a: 4, b: 14}, {a: 5, b: 15}, {a: 6, b: 16}, {a: 7, b: 17},\n     *   {a: 8, b: 18}]).batch(4);\n     * await c.forEachAsync(e => {\n     *   console.log('{');\n     *   for(var key in e) {\n     *     console.log(key+':');\n     *     e[key].print();\n     *   }\n     *   console.log('}');\n     * })\n     * ```\n     *\n     * @param batchSize The number of elements desired per batch.\n     * @param smallLastBatch Whether to emit the final batch when it has fewer\n     *   than batchSize elements. Default true.\n     * @returns A `Dataset`, from which a stream of batches can be obtained.\n     *\n     * @doc {heading: 'Data', subheading: 'Classes'}\n     */\n    batch(batchSize, smallLastBatch = true) {\n      const base = this;\n      tf.util.assert(batchSize > 0, () => `batchSize needs to be positive, but it is\n      ${batchSize}`);\n      let size;\n      if (this.size === Infinity || this.size == null) {\n        // If the size of this dataset is infinity or null, the new size keeps the\n        // same.\n        size = this.size;\n      } else if (smallLastBatch) {\n        // If the size of this dataset is known and include small last batch, the\n        // new size is full batch count plus last batch.\n        size = Math.ceil(this.size / batchSize);\n      } else {\n        // If the size of this dataset is known and not include small last batch,\n        // the new size is full batch count.\n        size = Math.floor(this.size / batchSize);\n      }\n      return datasetFromIteratorFn(async () => {\n        return (await base.iterator()).columnMajorBatch(batchSize, smallLastBatch, deepBatchConcat);\n      }, size);\n    }\n    /**\n     * Concatenates this `Dataset` with another.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3]);\n     * const b = tf.data.array([4, 5, 6]);\n     * const c = a.concatenate(b);\n     * await c.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param dataset A `Dataset` to be concatenated onto this one.\n     * @returns A `Dataset`.\n     *\n     * @doc {heading: 'Data', subheading: 'Classes'}\n     */\n    concatenate(dataset) {\n      const base = this;\n      let size;\n      if (this.size === Infinity || dataset.size === Infinity) {\n        // If the size of any of these two dataset is infinity, new size is\n        // infinity.\n        size = Infinity;\n      } else if (this.size != null && dataset.size != null) {\n        // If the size of both datasets are known and not infinity, new size is\n        // sum the size of these two datasets.\n        size = this.size + dataset.size;\n      } else {\n        // If neither of these two datasets has infinite size and any of these two\n        // datasets' size is null, the new size is null.\n        size = null;\n      }\n      return datasetFromIteratorFn(async () => (await base.iterator()).concatenate(await dataset.iterator()), size);\n    }\n    /**\n     * Filters this dataset according to `predicate`.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n     *   .filter(x => x%2 === 0);\n     * await a.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param predicate A function mapping a dataset element to a boolean or a\n     * `Promise` for one.\n     *\n     * @returns A `Dataset` of elements for which the predicate was true.\n     *\n     * @doc {heading: 'Data', subheading: 'Classes'}\n     */\n    filter(predicate) {\n      const base = this;\n      let size;\n      if (this.size === Infinity) {\n        // If the size of this dataset is infinity, new size is infinity\n        size = Infinity;\n      } else {\n        // If this dataset has limited elements, new size is null because it might\n        // exhausted randomly.\n        size = null;\n      }\n      return datasetFromIteratorFn(async () => {\n        return (await base.iterator()).filter(x => tf.tidy(() => predicate(x)));\n      }, size);\n    }\n    /**\n     * Apply a function to every element of the dataset.\n     *\n     * After the function is applied to a dataset element, any Tensors contained\n     * within that element are disposed.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3]);\n     * await a.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param f A function to apply to each dataset element.\n     * @returns A `Promise` that resolves after all elements have been processed.\n     *\n     * @doc {heading: 'Data', subheading: 'Classes'}\n     */\n    async forEachAsync(f) {\n      return (await this.iterator()).forEachAsync(f);\n    }\n    /**\n     * Maps this dataset through a 1-to-1 transform.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3]).map(x => x*x);\n     * await a.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param transform A function mapping a dataset element to a transformed\n     *   dataset element.\n     *\n     * @returns A `Dataset` of transformed elements.\n     *\n     * @doc {heading: 'Data', subheading: 'Classes'}\n     */\n    map(transform) {\n      const base = this;\n      return datasetFromIteratorFn(async () => {\n        return (await base.iterator()).map(x => tf.tidy(() => transform(x)));\n      }, this.size);\n    }\n    /**\n     * Maps this dataset through an async 1-to-1 transform.\n     *\n     * ```js\n     * const a =\n     *  tf.data.array([1, 2, 3]).mapAsync(x => new Promise(function(resolve){\n     *    setTimeout(() => {\n     *      resolve(x * x);\n     *    }, Math.random()*1000 + 500);\n     *  }));\n     * console.log(await a.toArray());\n     * ```\n     *\n     * @param transform A function mapping a dataset element to a `Promise` for a\n     *   transformed dataset element.  This transform is responsible for disposing\n     *   any intermediate `Tensor`s, i.e. by wrapping its computation in\n     *   `tf.tidy()`; that cannot be automated here (as it is in the synchronous\n     *   `map()` case).\n     *\n     * @returns A `Dataset` of transformed elements.\n     *\n     * @doc {heading: 'Data', subheading: 'Classes'}\n     */\n    mapAsync(transform) {\n      const base = this;\n      return datasetFromIteratorFn(async () => {\n        return (await base.iterator()).mapAsync(transform);\n      }, this.size);\n    }\n    /**\n     *  Creates a `Dataset` that prefetches elements from this dataset.\n     *\n     * @param bufferSize: An integer specifying the number of elements to be\n     *   prefetched.\n     * @returns A `Dataset`.\n     *\n     * @doc {heading: 'Data', subheading: 'Classes'}\n     */\n    prefetch(bufferSize) {\n      if (bufferSize == null) {\n        throw new RangeError('`Dataset.prefetch()` requires bufferSize to be specified.');\n      }\n      const base = this;\n      return datasetFromIteratorFn(async () => (await base.iterator()).prefetch(bufferSize), this.size);\n    }\n    /**\n     * Repeats this dataset `count` times.\n     *\n     * NOTE: If this dataset is a function of global state (e.g. a random number\n     * generator), then different repetitions may produce different elements.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3]).repeat(3);\n     * await a.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param count: (Optional) An integer, representing the number of times\n     *   the dataset should be repeated. The default behavior (if `count` is\n     *   `undefined` or negative) is for the dataset be repeated indefinitely.\n     * @returns A `Dataset`.\n     *\n     * @doc {heading: 'Data', subheading: 'Classes'}\n     */\n    repeat(count) {\n      const base = this;\n      let size;\n      if (this.size != null && count > 0) {\n        // If this dataset has size and count is positive, new size is current\n        // size multiply count. This also covers the case that current size is\n        // infinity.\n        size = this.size * count;\n      } else if (count === 0) {\n        // If count is 0, new size is 0.\n        size = 0;\n      } else if (this.size != null && (count === undefined || count < 0)) {\n        // If this dataset has size and count is undefined or negative, the\n        // dataset will be repeated indefinitely and new size is infinity.\n        size = Infinity;\n      } else {\n        // If the size of this dataset is null, the new dataset's size is null.\n        size = null;\n      }\n      return datasetFromIteratorFn(async () => {\n        const iteratorIterator = (0, _iteratorsLazy_iterator.iteratorFromFunction)(async () => ({\n          value: await base.iterator(),\n          done: false\n        }));\n        return (0, _iteratorsLazy_iterator.iteratorFromConcatenated)(iteratorIterator.take(count));\n      }, size);\n    }\n    /**\n     * Creates a `Dataset` that skips `count` initial elements from this dataset.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3, 4, 5, 6]).skip(3);\n     * await a.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param count: The number of elements of this dataset that should be skipped\n     *   to form the new dataset.  If `count` is greater than the size of this\n     *   dataset, the new dataset will contain no elements.  If `count`\n     *   is `undefined` or negative, skips the entire dataset.\n     *\n     * @returns A `Dataset`.\n     *\n     * @doc {heading: 'Data', subheading: 'Classes'}\n     */\n    skip(count) {\n      const base = this;\n      let size;\n      if (this.size != null && count >= 0 && this.size >= count) {\n        // If the size of this dataset is greater than count, the new dataset's\n        // size is current size minus skipped size.This also covers the case that\n        // current size is infinity.\n        size = this.size - count;\n      } else if (this.size != null && (this.size < count || count === undefined || count < 0)) {\n        // If the size of this dataset is smaller than count, or count is\n        // undefined or negative, skips the entire dataset and the new size is 0.\n        size = 0;\n      } else {\n        // If the size of this dataset is null, the new dataset's size is null.\n        size = null;\n      }\n      return datasetFromIteratorFn(async () => (await base.iterator()).skip(count), size);\n    }\n    /**\n     * Pseudorandomly shuffles the elements of this dataset. This is done in a\n     * streaming manner, by sampling from a given number of prefetched elements.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3, 4, 5, 6]).shuffle(3);\n     * await a.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param bufferSize: An integer specifying the number of elements from this\n     *   dataset from which the new dataset will sample.\n     * @param seed: (Optional) An integer specifying the random seed that will\n     *   be used to create the distribution.\n     * @param reshuffleEachIteration: (Optional) A boolean, which if true\n     *   indicates that the dataset should be pseudorandomly reshuffled each time\n     *   it is iterated over. If false, elements will be returned in the same\n     *   shuffled order on each iteration. (Defaults to `true`.)\n     * @returns A `Dataset`.\n     *\n     * @doc {heading: 'Data', subheading: 'Classes'}\n     */\n    shuffle(bufferSize, seed, reshuffleEachIteration = true) {\n      if (bufferSize == null || bufferSize < 0) {\n        if (this.size == null) {\n          throw new RangeError('`Dataset.shuffle()` requires bufferSize to be specified.');\n        } else {\n          throw new RangeError('`Dataset.shuffle()` requires bufferSize to be specified.  ' + 'If your data fits in main memory (for regular JS objects), ' + 'and/or GPU memory (for `tf.Tensor`s), consider setting ' + `bufferSize to the dataset size (${this.size} elements)`);\n        }\n      }\n      const base = this;\n      const random = seedrandom.alea(seed || tf.util.now().toString());\n      return datasetFromIteratorFn(async () => {\n        let seed2 = random.int32();\n        if (reshuffleEachIteration) {\n          seed2 += random.int32();\n        }\n        return (await base.iterator()).shuffle(bufferSize, seed2.toString());\n      }, this.size);\n    }\n    /**\n     * Creates a `Dataset` with at most `count` initial elements from this\n     * dataset.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3, 4, 5, 6]).take(3);\n     * await a.forEachAsync(e => console.log(e));\n     * ```\n     *\n     * @param count: The number of elements of this dataset that should be taken\n     *   to form the new dataset.  If `count` is `undefined` or negative, or if\n     *   `count` is greater than the size of this dataset, the new dataset will\n     *   contain all elements of this dataset.\n     * @returns A `Dataset`.\n     *\n     * @doc {heading: 'Data', subheading: 'Classes'}\n     */\n    take(count) {\n      const base = this;\n      let size;\n      if (this.size != null && this.size > count) {\n        // If the size of this dataset is greater than count, the new dataset's\n        // size is count.\n        size = count;\n      } else if (this.size != null && this.size <= count) {\n        // If the size of this dataset is equal or smaller than count, the new\n        // dataset's size is the size of this dataset.\n        size = this.size;\n      } else {\n        // If the size of this dataset is null, the new dataset's size is null.\n        size = null;\n      }\n      return datasetFromIteratorFn(async () => (await base.iterator()).take(count), size);\n    }\n    /**\n     * Collect all elements of this dataset into an array.\n     *\n     * Obviously this will succeed only for small datasets that fit in memory.\n     * Useful for testing and generally should be avoided if possible.\n     *\n     * ```js\n     * const a = tf.data.array([1, 2, 3, 4, 5, 6]);\n     * console.log(await a.toArray());\n     * ```\n     *\n     * @returns A Promise for an array of elements, which will resolve\n     *   when a new stream has been obtained and fully consumed.\n     *\n     * @doc {heading: 'Data', subheading: 'Classes'}\n     */\n    async toArray() {\n      if (this.size === Infinity) {\n        throw new Error('Can not convert infinite data stream to array.');\n      }\n      return (await this.iterator()).toArray();\n    }\n    /**\n     * Collect all elements of this dataset into an array with prefetching 100\n     * elements. This is useful for testing, because the prefetch changes the\n     * order in which the Promises are resolved along the processing pipeline.\n     * This may help expose bugs where results are dependent on the order of\n     * Promise resolution rather than on the logical order of the stream (i.e.,\n     * due to hidden mutable state).\n     *\n     * @returns A Promise for an array of elements, which will resolve\n     *   when a new stream has been obtained and fully consumed.\n     */\n    async toArrayForTest() {\n      if (this.size === Infinity) {\n        throw new Error('Can not convert infinite data stream to array.');\n      }\n      return (await this.iterator()).toArrayForTest();\n    }\n  }\n  // TODO(soergel): deep sharded shuffle, where supported\n  Dataset.MAX_BUFFER_SIZE = 10000;\n  /**\n   * Create a `Dataset` defined by a provided iterator() function.\n   *\n   * ```js\n   * let i = -1;\n   * const func = () =>\n   *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n   * const iter = tf.data.iteratorFromFunction(func);\n   * const ds = tf.data.datasetFromIteratorFn(iter);\n   * await ds.forEachAsync(e => console.log(e));\n   * ```\n   */\n  function datasetFromIteratorFn(iteratorFn, size = null) {\n    return new class extends Dataset {\n      constructor() {\n        super(...arguments);\n        this.size = size;\n      }\n      /*\n       * Provide a new stream of elements.  Note this will also start new streams\n       * from any underlying `Dataset`s.\n       */\n      async iterator() {\n        return iteratorFn();\n      }\n    }();\n  }\n  /**\n   * Create a `Dataset` from an array of elements.\n   *\n   * Create a Dataset from an array of objects:\n   * ```js\n   * const a = tf.data.array([{'item': 1}, {'item': 2}, {'item': 3}]);\n   * await a.forEachAsync(e => console.log(e));\n   * ```\n   *\n   * Create a Dataset from an array of numbers:\n   * ```js\n   * const a = tf.data.array([4, 5, 6]);\n   * await a.forEachAsync(e => console.log(e));\n   * ```\n   * @param items An array of elements that will be parsed as items in a dataset.\n   *\n   * @doc {heading: 'Data', subheading: 'Creation', namespace: 'data'}\n   */\n  function array(items) {\n    return datasetFromIteratorFn(async () => (0, _iteratorsLazy_iterator.iteratorFromItems)(items), items.length);\n  }\n  /**\n   * Create a `Dataset` by zipping together an array, dict, or nested\n   * structure of `Dataset`s (and perhaps additional constants).\n   * The underlying datasets must provide elements in a consistent order such that\n   * they correspond.\n   *\n   * The number of elements in the resulting dataset is the same as the size of\n   * the smallest dataset in datasets.\n   *\n   * The nested structure of the `datasets` argument determines the\n   * structure of elements in the resulting iterator.\n   *\n   * Note this means that, given an array of two datasets that produce dict\n   * elements, the result is a dataset that produces elements that are arrays\n   * of two dicts:\n   *\n   * Zip an array of datasets:\n   * ```js\n   * console.log('Zip two datasets of objects:');\n   * const ds1 = tf.data.array([{a: 1}, {a: 2}, {a: 3}]);\n   * const ds2 = tf.data.array([{b: 4}, {b: 5}, {b: 6}]);\n   * const ds3 = tf.data.zip([ds1, ds2]);\n   * await ds3.forEachAsync(e => console.log(JSON.stringify(e)));\n   *\n   * // If the goal is to merge the dicts in order to produce elements like\n   * // {a: ..., b: ...}, this requires a second step such as:\n   * console.log('Merge the objects:');\n   * const ds4 = ds3.map(x => {return {a: x[0].a, b: x[1].b}});\n   * await ds4.forEachAsync(e => console.log(e));\n   * ```\n   *\n   * Zip a dict of datasets:\n   * ```js\n   * const a = tf.data.array([{a: 1}, {a: 2}, {a: 3}]);\n   * const b = tf.data.array([{b: 4}, {b: 5}, {b: 6}]);\n   * const c = tf.data.zip({c: a, d: b});\n   * await c.forEachAsync(e => console.log(JSON.stringify(e)));\n   * ```\n   *\n   * @doc {heading: 'Data', subheading: 'Operations', namespace: 'data'}\n   */\n  function zip(datasets) {\n    // manually type-check the argument for JS users\n    if (!(0, _utilDeep_map.isIterable)(datasets)) {\n      throw new Error('The argument to zip() must be an object or array.');\n    }\n    let size;\n    if (Array.isArray(datasets)) {\n      for (let i = 0; i < datasets.length; i++) {\n        size = size == null ? datasets[i].size : Math.min(size, datasets[i].size);\n      }\n    } else if (datasets instanceof Object) {\n      for (const ds in datasets) {\n        size = size == null ? datasets[ds].size : Math.min(size, datasets[ds].size);\n      }\n    }\n    return datasetFromIteratorFn(async () => {\n      const streams = await (0, _utilDeep_map.deepMapAndAwaitAll)(datasets, d => {\n        if (d instanceof Dataset) {\n          return {\n            value: d.iterator(),\n            recurse: false\n          };\n        } else if ((0, _utilDeep_map.isIterable)(d)) {\n          return {\n            value: null,\n            recurse: true\n          };\n        } else {\n          throw new Error('Leaves of the structure passed to zip() must be Datasets, ' + 'not primitives.');\n        }\n      });\n      return (0, _iteratorsLazy_iterator.iteratorFromZipped)(streams, _iteratorsLazy_iterator.ZipMismatchMode.SHORTEST);\n    }, size);\n  }\n  /**\n   * A zip function for use with deepZip, passed via the columnMajorBatch call.\n   *\n   * Accepts an array of identically-structured nested elements and either batches\n   * them (if they are primitives, numeric arrays, or Tensors) or requests\n   * recursion (if not).\n   */\n  // tslint:disable-next-line:no-any\n  function deepBatchConcat(rows) {\n    if (rows === null) {\n      return null;\n    }\n    // use the first item to decide whether to recurse or batch here.\n    const exampleRow = rows[0];\n    if ((0, _utilDeep_map.canTensorify)(exampleRow)) {\n      // rows is an array of primitives, Tensors, or arrays.  Batch them.\n      const value = batchConcat(rows);\n      return {\n        value,\n        recurse: false\n      };\n    }\n    // the example row is an object, so recurse into it.\n    return {\n      value: null,\n      recurse: true\n    };\n  }\n  /**\n   * Assembles a list of same-shaped numbers, number arrays, or Tensors\n   * into a single new Tensor where axis 0 is the batch dimension.\n   */\n  function batchConcat(arrays) {\n    if (arrays.length === 0) {\n      // We can't return an empty Tensor because we don't know the element shape.\n      throw new Error('Can\\'t make a batch of zero elements.');\n    }\n    if (arrays[0] instanceof tf.Tensor) {\n      // Input is an array of Tensors\n      return tf.stack(arrays);\n    } else {\n      // Input is a possibly-nested array of numbers.\n      return tf.tensor(arrays);\n    }\n  }\n});","lineCount":682,"map":[[22,2,496,0,"Object"],[22,8,496,0],[22,9,496,0,"defineProperty"],[22,23,496,0],[22,24,496,0,"exports"],[22,31,496,0],[23,4,496,0,"enumerable"],[23,14,496,0],[24,4,496,0,"get"],[24,7,496,0],[24,18,496,0,"get"],[24,19,496,0],[25,6,496,0],[25,13,496,9,"Dataset"],[25,20,496,16],[26,4,496,16],[27,2,496,16],[28,2,509,0,"exports"],[28,9,509,0],[28,10,509,0,"datasetFromIteratorFn"],[28,31,509,0],[28,34,509,0,"datasetFromIteratorFn"],[28,55,509,0],[29,2,542,0,"exports"],[29,9,542,0],[29,10,542,0,"array"],[29,15,542,0],[29,18,542,0,"array"],[29,23,542,0],[30,2,586,0,"exports"],[30,9,586,0],[30,10,586,0,"zip"],[30,13,586,0],[30,16,586,0,"zip"],[30,19,586,0],[31,2,18,0],[31,6,18,0,"_tensorflowTfjsCore"],[31,25,18,0],[31,28,18,0,"require"],[31,35,18,0],[31,36,18,0,"_dependencyMap"],[31,50,18,0],[32,2,18,0],[32,6,18,0,"tf"],[32,8,18,0],[32,11,18,0,"_interopNamespace"],[32,28,18,0],[32,29,18,0,"_tensorflowTfjsCore"],[32,48,18,0],[33,2,19,0],[33,6,19,0,"_seedrandom"],[33,17,19,0],[33,20,19,0,"require"],[33,27,19,0],[33,28,19,0,"_dependencyMap"],[33,42,19,0],[34,2,19,0],[34,6,19,0,"seedrandom"],[34,16,19,0],[34,19,19,0,"_interopNamespace"],[34,36,19,0],[34,37,19,0,"_seedrandom"],[34,48,19,0],[35,2,20,0],[35,6,20,0,"_iteratorsLazy_iterator"],[35,29,20,0],[35,32,20,0,"require"],[35,39,20,0],[35,40,20,0,"_dependencyMap"],[35,54,20,0],[36,2,21,0],[36,6,21,0,"_utilDeep_map"],[36,19,21,0],[36,22,21,0,"require"],[36,29,21,0],[36,30,21,0,"_dependencyMap"],[36,44,21,0],[37,2,1,0],[38,0,2,0],[39,0,3,0],[40,0,4,0],[41,0,5,0],[42,0,6,0],[43,0,7,0],[44,0,8,0],[45,0,9,0],[46,0,10,0],[47,0,11,0],[48,0,12,0],[49,0,13,0],[50,0,14,0],[51,0,15,0],[52,0,16,0],[53,0,17,0],[55,2,22,0],[56,2,23,0],[57,0,24,0],[58,0,25,0],[59,0,26,0],[60,0,27,0],[61,0,28,0],[62,0,29,0],[63,0,30,0],[64,0,31,0],[65,0,32,0],[66,0,33,0],[67,0,34,0],[68,0,35,0],[69,0,36,0],[70,0,37,0],[71,0,38,0],[72,0,39,0],[73,0,40,0],[74,0,41,0],[75,0,42,0],[76,0,43,0],[77,0,44,0],[78,0,45,0],[79,0,46,0],[80,0,47,0],[81,0,48,0],[82,0,49,0],[83,0,50,0],[84,2,51,0],[84,8,51,6,"Dataset"],[84,15,51,13],[84,16,51,14],[85,4,52,4,"constructor"],[85,15,52,15,"constructor"],[85,16,52,15],[85,18,52,18],[86,6,53,8],[86,10,53,12],[86,11,53,13,"size"],[86,15,53,17],[86,18,53,20],[86,22,53,24],[87,4,54,4],[88,4,55,4],[89,4,56,4],[90,4,57,4],[91,4,58,4],[92,4,59,4],[93,4,60,4],[94,0,61,0],[95,0,62,0],[96,0,63,0],[97,0,64,0],[98,0,65,0],[99,0,66,0],[100,0,67,0],[101,0,68,0],[102,0,69,0],[103,0,70,0],[104,0,71,0],[105,0,72,0],[106,0,73,0],[107,0,74,0],[108,0,75,0],[109,0,76,0],[110,0,77,0],[111,0,78,0],[112,0,79,0],[113,0,80,0],[114,0,81,0],[115,0,82,0],[116,0,83,0],[117,0,84,0],[118,0,85,0],[119,0,86,0],[120,0,87,0],[121,0,88,0],[122,0,89,0],[123,0,90,0],[124,0,91,0],[125,0,92,0],[126,0,93,0],[127,0,94,0],[128,0,95,0],[129,0,96,0],[130,0,97,0],[131,0,98,0],[132,0,99,0],[133,0,100,0],[134,0,101,0],[135,0,102,0],[136,0,103,0],[137,0,104,0],[138,0,105,0],[139,0,106,0],[140,0,107,0],[141,0,108,0],[142,0,109,0],[143,0,110,0],[144,0,111,0],[145,0,112,0],[146,0,113,0],[147,0,114,0],[148,4,115,4,"batch"],[148,9,115,9,"batch"],[148,10,115,10,"batchSize"],[148,19,115,19],[148,21,115,21,"smallLastBatch"],[148,35,115,35],[148,38,115,38],[148,42,115,42],[148,44,115,44],[149,6,116,8],[149,12,116,14,"base"],[149,16,116,18],[149,19,116,21],[149,23,116,25],[150,6,117,8,"tf"],[150,8,117,10],[150,9,117,11,"util"],[150,13,117,15],[150,14,117,16,"assert"],[150,20,117,22],[150,21,117,23,"batchSize"],[150,30,117,32],[150,33,117,35],[150,34,117,36],[150,36,117,38],[150,42,117,44],[151,0,118,0],[151,8,118,8,"batchSize"],[151,17,118,17],[151,19,118,19],[151,20,118,20],[152,6,119,8],[152,10,119,12,"size"],[152,14,119,16],[153,6,120,8],[153,10,120,12],[153,14,120,16],[153,15,120,17,"size"],[153,19,120,21],[153,24,120,26,"Infinity"],[153,32,120,34],[153,36,120,38],[153,40,120,42],[153,41,120,43,"size"],[153,45,120,47],[153,49,120,51],[153,53,120,55],[153,55,120,57],[154,8,121,12],[155,8,122,12],[156,8,123,12,"size"],[156,12,123,16],[156,15,123,19],[156,19,123,23],[156,20,123,24,"size"],[156,24,123,28],[157,6,124,8],[157,7,124,9],[157,13,125,13],[157,17,125,17,"smallLastBatch"],[157,31,125,31],[157,33,125,33],[158,8,126,12],[159,8,127,12],[160,8,128,12,"size"],[160,12,128,16],[160,15,128,19,"Math"],[160,19,128,23],[160,20,128,24,"ceil"],[160,24,128,28],[160,25,128,29],[160,29,128,33],[160,30,128,34,"size"],[160,34,128,38],[160,37,128,41,"batchSize"],[160,46,128,50],[160,47,128,51],[161,6,129,8],[161,7,129,9],[161,13,130,13],[162,8,131,12],[163,8,132,12],[164,8,133,12,"size"],[164,12,133,16],[164,15,133,19,"Math"],[164,19,133,23],[164,20,133,24,"floor"],[164,25,133,29],[164,26,133,30],[164,30,133,34],[164,31,133,35,"size"],[164,35,133,39],[164,38,133,42,"batchSize"],[164,47,133,51],[164,48,133,52],[165,6,134,8],[166,6,135,8],[166,13,135,15,"datasetFromIteratorFn"],[166,34,135,36],[166,35,135,37],[166,47,135,49],[167,8,136,12],[167,15,136,19],[167,16,136,20],[167,22,136,26,"base"],[167,26,136,30],[167,27,136,31,"iterator"],[167,35,136,39],[167,36,136,40],[167,37,136,41],[167,39,137,17,"columnMajorBatch"],[167,55,137,33],[167,56,137,34,"batchSize"],[167,65,137,43],[167,67,137,45,"smallLastBatch"],[167,81,137,59],[167,83,137,61,"deepBatchConcat"],[167,98,137,76],[167,99,137,77],[168,6,138,8],[168,7,138,9],[168,9,138,11,"size"],[168,13,138,15],[168,14,138,16],[169,4,139,4],[170,4,140,4],[171,0,141,0],[172,0,142,0],[173,0,143,0],[174,0,144,0],[175,0,145,0],[176,0,146,0],[177,0,147,0],[178,0,148,0],[179,0,149,0],[180,0,150,0],[181,0,151,0],[182,0,152,0],[183,0,153,0],[184,0,154,0],[185,4,155,4,"concatenate"],[185,15,155,15,"concatenate"],[185,16,155,16,"dataset"],[185,23,155,23],[185,25,155,25],[186,6,156,8],[186,12,156,14,"base"],[186,16,156,18],[186,19,156,21],[186,23,156,25],[187,6,157,8],[187,10,157,12,"size"],[187,14,157,16],[188,6,158,8],[188,10,158,12],[188,14,158,16],[188,15,158,17,"size"],[188,19,158,21],[188,24,158,26,"Infinity"],[188,32,158,34],[188,36,158,38,"dataset"],[188,43,158,45],[188,44,158,46,"size"],[188,48,158,50],[188,53,158,55,"Infinity"],[188,61,158,63],[188,63,158,65],[189,8,159,12],[190,8,160,12],[191,8,161,12,"size"],[191,12,161,16],[191,15,161,19,"Infinity"],[191,23,161,27],[192,6,162,8],[192,7,162,9],[192,13,163,13],[192,17,163,17],[192,21,163,21],[192,22,163,22,"size"],[192,26,163,26],[192,30,163,30],[192,34,163,34],[192,38,163,38,"dataset"],[192,45,163,45],[192,46,163,46,"size"],[192,50,163,50],[192,54,163,54],[192,58,163,58],[192,60,163,60],[193,8,164,12],[194,8,165,12],[195,8,166,12,"size"],[195,12,166,16],[195,15,166,19],[195,19,166,23],[195,20,166,24,"size"],[195,24,166,28],[195,27,166,31,"dataset"],[195,34,166,38],[195,35,166,39,"size"],[195,39,166,43],[196,6,167,8],[196,7,167,9],[196,13,168,13],[197,8,169,12],[198,8,170,12],[199,8,171,12,"size"],[199,12,171,16],[199,15,171,19],[199,19,171,23],[200,6,172,8],[201,6,173,8],[201,13,173,15,"datasetFromIteratorFn"],[201,34,173,36],[201,35,173,37],[201,47,173,49],[201,48,173,50],[201,54,173,56,"base"],[201,58,173,60],[201,59,173,61,"iterator"],[201,67,173,69],[201,68,173,70],[201,69,173,71],[201,71,173,73,"concatenate"],[201,82,173,84],[201,83,173,85],[201,89,173,91,"dataset"],[201,96,173,98],[201,97,173,99,"iterator"],[201,105,173,107],[201,106,173,108],[201,107,173,109],[201,108,173,110],[201,110,173,112,"size"],[201,114,173,116],[201,115,173,117],[202,4,174,4],[203,4,175,4],[204,0,176,0],[205,0,177,0],[206,0,178,0],[207,0,179,0],[208,0,180,0],[209,0,181,0],[210,0,182,0],[211,0,183,0],[212,0,184,0],[213,0,185,0],[214,0,186,0],[215,0,187,0],[216,0,188,0],[217,0,189,0],[218,0,190,0],[219,4,191,4,"filter"],[219,10,191,10,"filter"],[219,11,191,11,"predicate"],[219,20,191,20],[219,22,191,22],[220,6,192,8],[220,12,192,14,"base"],[220,16,192,18],[220,19,192,21],[220,23,192,25],[221,6,193,8],[221,10,193,12,"size"],[221,14,193,16],[222,6,194,8],[222,10,194,12],[222,14,194,16],[222,15,194,17,"size"],[222,19,194,21],[222,24,194,26,"Infinity"],[222,32,194,34],[222,34,194,36],[223,8,195,12],[224,8,196,12,"size"],[224,12,196,16],[224,15,196,19,"Infinity"],[224,23,196,27],[225,6,197,8],[225,7,197,9],[225,13,198,13],[226,8,199,12],[227,8,200,12],[228,8,201,12,"size"],[228,12,201,16],[228,15,201,19],[228,19,201,23],[229,6,202,8],[230,6,203,8],[230,13,203,15,"datasetFromIteratorFn"],[230,34,203,36],[230,35,203,37],[230,47,203,49],[231,8,204,12],[231,15,204,19],[231,16,204,20],[231,22,204,26,"base"],[231,26,204,30],[231,27,204,31,"iterator"],[231,35,204,39],[231,36,204,40],[231,37,204,41],[231,39,204,43,"filter"],[231,45,204,49],[231,46,204,50,"x"],[231,47,204,51],[231,51,204,55,"tf"],[231,53,204,57],[231,54,204,58,"tidy"],[231,58,204,62],[231,59,204,63],[231,65,204,69,"predicate"],[231,74,204,78],[231,75,204,79,"x"],[231,76,204,80],[231,77,204,81],[231,78,204,82],[231,79,204,83],[232,6,205,8],[232,7,205,9],[232,9,205,11,"size"],[232,13,205,15],[232,14,205,16],[233,4,206,4],[234,4,207,4],[235,0,208,0],[236,0,209,0],[237,0,210,0],[238,0,211,0],[239,0,212,0],[240,0,213,0],[241,0,214,0],[242,0,215,0],[243,0,216,0],[244,0,217,0],[245,0,218,0],[246,0,219,0],[247,0,220,0],[248,0,221,0],[249,0,222,0],[250,4,223,4],[250,10,223,10,"forEachAsync"],[250,22,223,22,"forEachAsync"],[250,23,223,23,"f"],[250,24,223,24],[250,26,223,26],[251,6,224,8],[251,13,224,15],[251,14,224,16],[251,20,224,22],[251,24,224,26],[251,25,224,27,"iterator"],[251,33,224,35],[251,34,224,36],[251,35,224,37],[251,37,224,39,"forEachAsync"],[251,49,224,51],[251,50,224,52,"f"],[251,51,224,53],[251,52,224,54],[252,4,225,4],[253,4,226,4],[254,0,227,0],[255,0,228,0],[256,0,229,0],[257,0,230,0],[258,0,231,0],[259,0,232,0],[260,0,233,0],[261,0,234,0],[262,0,235,0],[263,0,236,0],[264,0,237,0],[265,0,238,0],[266,0,239,0],[267,0,240,0],[268,4,241,4,"map"],[268,7,241,7,"map"],[268,8,241,8,"transform"],[268,17,241,17],[268,19,241,19],[269,6,242,8],[269,12,242,14,"base"],[269,16,242,18],[269,19,242,21],[269,23,242,25],[270,6,243,8],[270,13,243,15,"datasetFromIteratorFn"],[270,34,243,36],[270,35,243,37],[270,47,243,49],[271,8,244,12],[271,15,244,19],[271,16,244,20],[271,22,244,26,"base"],[271,26,244,30],[271,27,244,31,"iterator"],[271,35,244,39],[271,36,244,40],[271,37,244,41],[271,39,244,43,"map"],[271,42,244,46],[271,43,244,47,"x"],[271,44,244,48],[271,48,244,52,"tf"],[271,50,244,54],[271,51,244,55,"tidy"],[271,55,244,59],[271,56,244,60],[271,62,244,66,"transform"],[271,71,244,75],[271,72,244,76,"x"],[271,73,244,77],[271,74,244,78],[271,75,244,79],[271,76,244,80],[272,6,245,8],[272,7,245,9],[272,9,245,11],[272,13,245,15],[272,14,245,16,"size"],[272,18,245,20],[272,19,245,21],[273,4,246,4],[274,4,247,4],[275,0,248,0],[276,0,249,0],[277,0,250,0],[278,0,251,0],[279,0,252,0],[280,0,253,0],[281,0,254,0],[282,0,255,0],[283,0,256,0],[284,0,257,0],[285,0,258,0],[286,0,259,0],[287,0,260,0],[288,0,261,0],[289,0,262,0],[290,0,263,0],[291,0,264,0],[292,0,265,0],[293,0,266,0],[294,0,267,0],[295,0,268,0],[296,0,269,0],[297,4,270,4,"mapAsync"],[297,12,270,12,"mapAsync"],[297,13,270,13,"transform"],[297,22,270,22],[297,24,270,24],[298,6,271,8],[298,12,271,14,"base"],[298,16,271,18],[298,19,271,21],[298,23,271,25],[299,6,272,8],[299,13,272,15,"datasetFromIteratorFn"],[299,34,272,36],[299,35,272,37],[299,47,272,49],[300,8,273,12],[300,15,273,19],[300,16,273,20],[300,22,273,26,"base"],[300,26,273,30],[300,27,273,31,"iterator"],[300,35,273,39],[300,36,273,40],[300,37,273,41],[300,39,273,43,"mapAsync"],[300,47,273,51],[300,48,273,52,"transform"],[300,57,273,61],[300,58,273,62],[301,6,274,8],[301,7,274,9],[301,9,274,11],[301,13,274,15],[301,14,274,16,"size"],[301,18,274,20],[301,19,274,21],[302,4,275,4],[303,4,276,4],[304,0,277,0],[305,0,278,0],[306,0,279,0],[307,0,280,0],[308,0,281,0],[309,0,282,0],[310,0,283,0],[311,0,284,0],[312,4,285,4,"prefetch"],[312,12,285,12,"prefetch"],[312,13,285,13,"bufferSize"],[312,23,285,23],[312,25,285,25],[313,6,286,8],[313,10,286,12,"bufferSize"],[313,20,286,22],[313,24,286,26],[313,28,286,30],[313,30,286,32],[314,8,287,12],[314,14,287,18],[314,18,287,22,"RangeError"],[314,28,287,32],[314,29,287,33],[314,88,287,92],[314,89,287,93],[315,6,288,8],[316,6,289,8],[316,12,289,14,"base"],[316,16,289,18],[316,19,289,21],[316,23,289,25],[317,6,290,8],[317,13,290,15,"datasetFromIteratorFn"],[317,34,290,36],[317,35,290,37],[317,47,290,49],[317,48,290,50],[317,54,290,56,"base"],[317,58,290,60],[317,59,290,61,"iterator"],[317,67,290,69],[317,68,290,70],[317,69,290,71],[317,71,290,73,"prefetch"],[317,79,290,81],[317,80,290,82,"bufferSize"],[317,90,290,92],[317,91,290,93],[317,93,290,95],[317,97,290,99],[317,98,290,100,"size"],[317,102,290,104],[317,103,290,105],[318,4,291,4],[319,4,292,4],[320,0,293,0],[321,0,294,0],[322,0,295,0],[323,0,296,0],[324,0,297,0],[325,0,298,0],[326,0,299,0],[327,0,300,0],[328,0,301,0],[329,0,302,0],[330,0,303,0],[331,0,304,0],[332,0,305,0],[333,0,306,0],[334,0,307,0],[335,0,308,0],[336,0,309,0],[337,4,310,4,"repeat"],[337,10,310,10,"repeat"],[337,11,310,11,"count"],[337,16,310,16],[337,18,310,18],[338,6,311,8],[338,12,311,14,"base"],[338,16,311,18],[338,19,311,21],[338,23,311,25],[339,6,312,8],[339,10,312,12,"size"],[339,14,312,16],[340,6,313,8],[340,10,313,12],[340,14,313,16],[340,15,313,17,"size"],[340,19,313,21],[340,23,313,25],[340,27,313,29],[340,31,313,33,"count"],[340,36,313,38],[340,39,313,41],[340,40,313,42],[340,42,313,44],[341,8,314,12],[342,8,315,12],[343,8,316,12],[344,8,317,12,"size"],[344,12,317,16],[344,15,317,19],[344,19,317,23],[344,20,317,24,"size"],[344,24,317,28],[344,27,317,31,"count"],[344,32,317,36],[345,6,318,8],[345,7,318,9],[345,13,319,13],[345,17,319,17,"count"],[345,22,319,22],[345,27,319,27],[345,28,319,28],[345,30,319,30],[346,8,320,12],[347,8,321,12,"size"],[347,12,321,16],[347,15,321,19],[347,16,321,20],[348,6,322,8],[348,7,322,9],[348,13,323,13],[348,17,323,17],[348,21,323,21],[348,22,323,22,"size"],[348,26,323,26],[348,30,323,30],[348,34,323,34],[348,39,323,39,"count"],[348,44,323,44],[348,49,323,49,"undefined"],[348,58,323,58],[348,62,323,62,"count"],[348,67,323,67],[348,70,323,70],[348,71,323,71],[348,72,323,72],[348,74,323,74],[349,8,324,12],[350,8,325,12],[351,8,326,12,"size"],[351,12,326,16],[351,15,326,19,"Infinity"],[351,23,326,27],[352,6,327,8],[352,7,327,9],[352,13,328,13],[353,8,329,12],[354,8,330,12,"size"],[354,12,330,16],[354,15,330,19],[354,19,330,23],[355,6,331,8],[356,6,332,8],[356,13,332,15,"datasetFromIteratorFn"],[356,34,332,36],[356,35,332,37],[356,47,332,49],[357,8,333,12],[357,14,333,18,"iteratorIterator"],[357,30,333,34],[357,33,333,37],[357,37,333,37,"iteratorFromFunction"],[357,60,333,57],[357,61,333,57,"iteratorFromFunction"],[357,81,333,57],[357,83,333,58],[357,96,333,71],[358,10,333,73,"value"],[358,15,333,78],[358,17,333,80],[358,23,333,86,"base"],[358,27,333,90],[358,28,333,91,"iterator"],[358,36,333,99],[358,37,333,100],[358,38,333,101],[359,10,333,103,"done"],[359,14,333,107],[359,16,333,109],[360,8,333,115],[360,9,333,116],[360,10,333,117],[360,11,333,118],[361,8,334,12],[361,15,334,19],[361,19,334,19,"iteratorFromConcatenated"],[361,42,334,43],[361,43,334,43,"iteratorFromConcatenated"],[361,67,334,43],[361,69,334,44,"iteratorIterator"],[361,85,334,60],[361,86,334,61,"take"],[361,90,334,65],[361,91,334,66,"count"],[361,96,334,71],[361,97,334,72],[361,98,334,73],[362,6,335,8],[362,7,335,9],[362,9,335,11,"size"],[362,13,335,15],[362,14,335,16],[363,4,336,4],[364,4,337,4],[365,0,338,0],[366,0,339,0],[367,0,340,0],[368,0,341,0],[369,0,342,0],[370,0,343,0],[371,0,344,0],[372,0,345,0],[373,0,346,0],[374,0,347,0],[375,0,348,0],[376,0,349,0],[377,0,350,0],[378,0,351,0],[379,0,352,0],[380,0,353,0],[381,4,354,4,"skip"],[381,8,354,8,"skip"],[381,9,354,9,"count"],[381,14,354,14],[381,16,354,16],[382,6,355,8],[382,12,355,14,"base"],[382,16,355,18],[382,19,355,21],[382,23,355,25],[383,6,356,8],[383,10,356,12,"size"],[383,14,356,16],[384,6,357,8],[384,10,357,12],[384,14,357,16],[384,15,357,17,"size"],[384,19,357,21],[384,23,357,25],[384,27,357,29],[384,31,357,33,"count"],[384,36,357,38],[384,40,357,42],[384,41,357,43],[384,45,357,47],[384,49,357,51],[384,50,357,52,"size"],[384,54,357,56],[384,58,357,60,"count"],[384,63,357,65],[384,65,357,67],[385,8,358,12],[386,8,359,12],[387,8,360,12],[388,8,361,12,"size"],[388,12,361,16],[388,15,361,19],[388,19,361,23],[388,20,361,24,"size"],[388,24,361,28],[388,27,361,31,"count"],[388,32,361,36],[389,6,362,8],[389,7,362,9],[389,13,363,13],[389,17,363,17],[389,21,363,21],[389,22,363,22,"size"],[389,26,363,26],[389,30,363,30],[389,34,363,34],[389,39,364,13],[389,43,364,17],[389,44,364,18,"size"],[389,48,364,22],[389,51,364,25,"count"],[389,56,364,30],[389,60,364,34,"count"],[389,65,364,39],[389,70,364,44,"undefined"],[389,79,364,53],[389,83,364,57,"count"],[389,88,364,62],[389,91,364,65],[389,92,364,66],[389,93,364,67],[389,95,364,69],[390,8,365,12],[391,8,366,12],[392,8,367,12,"size"],[392,12,367,16],[392,15,367,19],[392,16,367,20],[393,6,368,8],[393,7,368,9],[393,13,369,13],[394,8,370,12],[395,8,371,12,"size"],[395,12,371,16],[395,15,371,19],[395,19,371,23],[396,6,372,8],[397,6,373,8],[397,13,373,15,"datasetFromIteratorFn"],[397,34,373,36],[397,35,373,37],[397,47,373,49],[397,48,373,50],[397,54,373,56,"base"],[397,58,373,60],[397,59,373,61,"iterator"],[397,67,373,69],[397,68,373,70],[397,69,373,71],[397,71,373,73,"skip"],[397,75,373,77],[397,76,373,78,"count"],[397,81,373,83],[397,82,373,84],[397,84,373,86,"size"],[397,88,373,90],[397,89,373,91],[398,4,374,4],[399,4,375,4],[400,0,376,0],[401,0,377,0],[402,0,378,0],[403,0,379,0],[404,0,380,0],[405,0,381,0],[406,0,382,0],[407,0,383,0],[408,0,384,0],[409,0,385,0],[410,0,386,0],[411,0,387,0],[412,0,388,0],[413,0,389,0],[414,0,390,0],[415,0,391,0],[416,0,392,0],[417,0,393,0],[418,0,394,0],[419,0,395,0],[420,4,396,4,"shuffle"],[420,11,396,11,"shuffle"],[420,12,396,12,"bufferSize"],[420,22,396,22],[420,24,396,24,"seed"],[420,28,396,28],[420,30,396,30,"reshuffleEachIteration"],[420,52,396,52],[420,55,396,55],[420,59,396,59],[420,61,396,61],[421,6,397,8],[421,10,397,12,"bufferSize"],[421,20,397,22],[421,24,397,26],[421,28,397,30],[421,32,397,34,"bufferSize"],[421,42,397,44],[421,45,397,47],[421,46,397,48],[421,48,397,50],[422,8,398,12],[422,12,398,16],[422,16,398,20],[422,17,398,21,"size"],[422,21,398,25],[422,25,398,29],[422,29,398,33],[422,31,398,35],[423,10,399,16],[423,16,399,22],[423,20,399,26,"RangeError"],[423,30,399,36],[423,31,399,37],[423,89,399,95],[423,90,399,96],[424,8,400,12],[424,9,400,13],[424,15,401,17],[425,10,402,16],[425,16,402,22],[425,20,402,26,"RangeError"],[425,30,402,36],[425,31,402,37],[425,91,402,97],[425,94,403,20],[425,155,403,81],[425,158,404,20],[425,215,404,77],[425,218,405,20],[425,253,405,55],[425,257,405,59],[425,258,405,60,"size"],[425,262,405,64],[425,274,405,76],[425,275,405,77],[426,8,406,12],[427,6,407,8],[428,6,408,8],[428,12,408,14,"base"],[428,16,408,18],[428,19,408,21],[428,23,408,25],[429,6,409,8],[429,12,409,14,"random"],[429,18,409,20],[429,21,409,23,"seedrandom"],[429,31,409,33],[429,32,409,34,"alea"],[429,36,409,38],[429,37,409,39,"seed"],[429,41,409,43],[429,45,409,47,"tf"],[429,47,409,49],[429,48,409,50,"util"],[429,52,409,54],[429,53,409,55,"now"],[429,56,409,58],[429,57,409,59],[429,58,409,60],[429,59,409,61,"toString"],[429,67,409,69],[429,68,409,70],[429,69,409,71],[429,70,409,72],[430,6,410,8],[430,13,410,15,"datasetFromIteratorFn"],[430,34,410,36],[430,35,410,37],[430,47,410,49],[431,8,411,12],[431,12,411,16,"seed2"],[431,17,411,21],[431,20,411,24,"random"],[431,26,411,30],[431,27,411,31,"int32"],[431,32,411,36],[431,33,411,37],[431,34,411,38],[432,8,412,12],[432,12,412,16,"reshuffleEachIteration"],[432,34,412,38],[432,36,412,40],[433,10,413,16,"seed2"],[433,15,413,21],[433,19,413,25,"random"],[433,25,413,31],[433,26,413,32,"int32"],[433,31,413,37],[433,32,413,38],[433,33,413,39],[434,8,414,12],[435,8,415,12],[435,15,415,19],[435,16,415,20],[435,22,415,26,"base"],[435,26,415,30],[435,27,415,31,"iterator"],[435,35,415,39],[435,36,415,40],[435,37,415,41],[435,39,415,43,"shuffle"],[435,46,415,50],[435,47,415,51,"bufferSize"],[435,57,415,61],[435,59,415,63,"seed2"],[435,64,415,68],[435,65,415,69,"toString"],[435,73,415,77],[435,74,415,78],[435,75,415,79],[435,76,415,80],[436,6,416,8],[436,7,416,9],[436,9,416,11],[436,13,416,15],[436,14,416,16,"size"],[436,18,416,20],[436,19,416,21],[437,4,417,4],[438,4,418,4],[439,0,419,0],[440,0,420,0],[441,0,421,0],[442,0,422,0],[443,0,423,0],[444,0,424,0],[445,0,425,0],[446,0,426,0],[447,0,427,0],[448,0,428,0],[449,0,429,0],[450,0,430,0],[451,0,431,0],[452,0,432,0],[453,0,433,0],[454,0,434,0],[455,4,435,4,"take"],[455,8,435,8,"take"],[455,9,435,9,"count"],[455,14,435,14],[455,16,435,16],[456,6,436,8],[456,12,436,14,"base"],[456,16,436,18],[456,19,436,21],[456,23,436,25],[457,6,437,8],[457,10,437,12,"size"],[457,14,437,16],[458,6,438,8],[458,10,438,12],[458,14,438,16],[458,15,438,17,"size"],[458,19,438,21],[458,23,438,25],[458,27,438,29],[458,31,438,33],[458,35,438,37],[458,36,438,38,"size"],[458,40,438,42],[458,43,438,45,"count"],[458,48,438,50],[458,50,438,52],[459,8,439,12],[460,8,440,12],[461,8,441,12,"size"],[461,12,441,16],[461,15,441,19,"count"],[461,20,441,24],[462,6,442,8],[462,7,442,9],[462,13,443,13],[462,17,443,17],[462,21,443,21],[462,22,443,22,"size"],[462,26,443,26],[462,30,443,30],[462,34,443,34],[462,38,443,38],[462,42,443,42],[462,43,443,43,"size"],[462,47,443,47],[462,51,443,51,"count"],[462,56,443,56],[462,58,443,58],[463,8,444,12],[464,8,445,12],[465,8,446,12,"size"],[465,12,446,16],[465,15,446,19],[465,19,446,23],[465,20,446,24,"size"],[465,24,446,28],[466,6,447,8],[466,7,447,9],[466,13,448,13],[467,8,449,12],[468,8,450,12,"size"],[468,12,450,16],[468,15,450,19],[468,19,450,23],[469,6,451,8],[470,6,452,8],[470,13,452,15,"datasetFromIteratorFn"],[470,34,452,36],[470,35,452,37],[470,47,452,49],[470,48,452,50],[470,54,452,56,"base"],[470,58,452,60],[470,59,452,61,"iterator"],[470,67,452,69],[470,68,452,70],[470,69,452,71],[470,71,452,73,"take"],[470,75,452,77],[470,76,452,78,"count"],[470,81,452,83],[470,82,452,84],[470,84,452,86,"size"],[470,88,452,90],[470,89,452,91],[471,4,453,4],[472,4,454,4],[473,0,455,0],[474,0,456,0],[475,0,457,0],[476,0,458,0],[477,0,459,0],[478,0,460,0],[479,0,461,0],[480,0,462,0],[481,0,463,0],[482,0,464,0],[483,0,465,0],[484,0,466,0],[485,0,467,0],[486,0,468,0],[487,0,469,0],[488,4,470,4],[488,10,470,10,"toArray"],[488,17,470,17,"toArray"],[488,18,470,17],[488,20,470,20],[489,6,471,8],[489,10,471,12],[489,14,471,16],[489,15,471,17,"size"],[489,19,471,21],[489,24,471,26,"Infinity"],[489,32,471,34],[489,34,471,36],[490,8,472,12],[490,14,472,18],[490,18,472,22,"Error"],[490,23,472,27],[490,24,472,28],[490,72,472,76],[490,73,472,77],[491,6,473,8],[492,6,474,8],[492,13,474,15],[492,14,474,16],[492,20,474,22],[492,24,474,26],[492,25,474,27,"iterator"],[492,33,474,35],[492,34,474,36],[492,35,474,37],[492,37,474,39,"toArray"],[492,44,474,46],[492,45,474,47],[492,46,474,48],[493,4,475,4],[494,4,476,4],[495,0,477,0],[496,0,478,0],[497,0,479,0],[498,0,480,0],[499,0,481,0],[500,0,482,0],[501,0,483,0],[502,0,484,0],[503,0,485,0],[504,0,486,0],[505,4,487,4],[505,10,487,10,"toArrayForTest"],[505,24,487,24,"toArrayForTest"],[505,25,487,24],[505,27,487,27],[506,6,488,8],[506,10,488,12],[506,14,488,16],[506,15,488,17,"size"],[506,19,488,21],[506,24,488,26,"Infinity"],[506,32,488,34],[506,34,488,36],[507,8,489,12],[507,14,489,18],[507,18,489,22,"Error"],[507,23,489,27],[507,24,489,28],[507,72,489,76],[507,73,489,77],[508,6,490,8],[509,6,491,8],[509,13,491,15],[509,14,491,16],[509,20,491,22],[509,24,491,26],[509,25,491,27,"iterator"],[509,33,491,35],[509,34,491,36],[509,35,491,37],[509,37,491,39,"toArrayForTest"],[509,51,491,53],[509,52,491,54],[509,53,491,55],[510,4,492,4],[511,2,493,0],[512,2,494,0],[513,2,495,0,"Dataset"],[513,9,495,7],[513,10,495,8,"MAX_BUFFER_SIZE"],[513,25,495,23],[513,28,495,26],[513,33,495,31],[514,2,497,0],[515,0,498,0],[516,0,499,0],[517,0,500,0],[518,0,501,0],[519,0,502,0],[520,0,503,0],[521,0,504,0],[522,0,505,0],[523,0,506,0],[524,0,507,0],[525,0,508,0],[526,2,509,7],[526,11,509,16,"datasetFromIteratorFn"],[526,32,509,37,"datasetFromIteratorFn"],[526,33,509,38,"iteratorFn"],[526,43,509,48],[526,45,509,50,"size"],[526,49,509,54],[526,52,509,57],[526,56,509,61],[526,58,509,63],[527,4,510,4],[527,11,510,11],[527,15,510,15],[527,29,510,29,"Dataset"],[527,36,510,36],[527,37,510,37],[528,6,511,8,"constructor"],[528,17,511,19,"constructor"],[528,18,511,19],[528,20,511,22],[529,8,512,12],[529,13,512,17],[529,14,512,18],[529,17,512,21,"arguments"],[529,26,512,30],[529,27,512,31],[530,8,513,12],[530,12,513,16],[530,13,513,17,"size"],[530,17,513,21],[530,20,513,24,"size"],[530,24,513,28],[531,6,514,8],[532,6,515,8],[533,0,516,0],[534,0,517,0],[535,0,518,0],[536,6,519,8],[536,12,519,14,"iterator"],[536,20,519,22,"iterator"],[536,21,519,22],[536,23,519,25],[537,8,520,12],[537,15,520,19,"iteratorFn"],[537,25,520,29],[537,26,520,30],[537,27,520,31],[538,6,521,8],[539,4,522,4],[539,5,522,5],[539,6,522,6],[539,7,522,7],[540,2,523,0],[541,2,524,0],[542,0,525,0],[543,0,526,0],[544,0,527,0],[545,0,528,0],[546,0,529,0],[547,0,530,0],[548,0,531,0],[549,0,532,0],[550,0,533,0],[551,0,534,0],[552,0,535,0],[553,0,536,0],[554,0,537,0],[555,0,538,0],[556,0,539,0],[557,0,540,0],[558,0,541,0],[559,2,542,7],[559,11,542,16,"array"],[559,16,542,21,"array"],[559,17,542,22,"items"],[559,22,542,27],[559,24,542,29],[560,4,543,4],[560,11,543,11,"datasetFromIteratorFn"],[560,32,543,32],[560,33,543,33],[560,45,543,45],[560,49,543,45,"iteratorFromItems"],[560,72,543,62],[560,73,543,62,"iteratorFromItems"],[560,90,543,62],[560,92,543,63,"items"],[560,97,543,68],[560,98,543,69],[560,100,543,71,"items"],[560,105,543,76],[560,106,543,77,"length"],[560,112,543,83],[560,113,543,84],[561,2,544,0],[562,2,545,0],[563,0,546,0],[564,0,547,0],[565,0,548,0],[566,0,549,0],[567,0,550,0],[568,0,551,0],[569,0,552,0],[570,0,553,0],[571,0,554,0],[572,0,555,0],[573,0,556,0],[574,0,557,0],[575,0,558,0],[576,0,559,0],[577,0,560,0],[578,0,561,0],[579,0,562,0],[580,0,563,0],[581,0,564,0],[582,0,565,0],[583,0,566,0],[584,0,567,0],[585,0,568,0],[586,0,569,0],[587,0,570,0],[588,0,571,0],[589,0,572,0],[590,0,573,0],[591,0,574,0],[592,0,575,0],[593,0,576,0],[594,0,577,0],[595,0,578,0],[596,0,579,0],[597,0,580,0],[598,0,581,0],[599,0,582,0],[600,0,583,0],[601,0,584,0],[602,0,585,0],[603,2,586,7],[603,11,586,16,"zip"],[603,14,586,19,"zip"],[603,15,586,20,"datasets"],[603,23,586,28],[603,25,586,30],[604,4,587,4],[605,4,588,4],[605,8,588,8],[605,9,588,9],[605,13,588,9,"isIterable"],[605,26,588,19],[605,27,588,19,"isIterable"],[605,37,588,19],[605,39,588,20,"datasets"],[605,47,588,28],[605,48,588,29],[605,50,588,31],[606,6,589,8],[606,12,589,14],[606,16,589,18,"Error"],[606,21,589,23],[606,22,589,24],[606,73,589,75],[606,74,589,76],[607,4,590,4],[608,4,591,4],[608,8,591,8,"size"],[608,12,591,12],[609,4,592,4],[609,8,592,8,"Array"],[609,13,592,13],[609,14,592,14,"isArray"],[609,21,592,21],[609,22,592,22,"datasets"],[609,30,592,30],[609,31,592,31],[609,33,592,33],[610,6,593,8],[610,11,593,13],[610,15,593,17,"i"],[610,16,593,18],[610,19,593,21],[610,20,593,22],[610,22,593,24,"i"],[610,23,593,25],[610,26,593,28,"datasets"],[610,34,593,36],[610,35,593,37,"length"],[610,41,593,43],[610,43,593,45,"i"],[610,44,593,46],[610,46,593,48],[610,48,593,50],[611,8,594,12,"size"],[611,12,594,16],[611,15,594,19,"size"],[611,19,594,23],[611,23,594,27],[611,27,594,31],[611,30,594,34,"datasets"],[611,38,594,42],[611,39,594,43,"i"],[611,40,594,44],[611,41,594,45],[611,42,594,46,"size"],[611,46,594,50],[611,49,595,16,"Math"],[611,53,595,20],[611,54,595,21,"min"],[611,57,595,24],[611,58,595,25,"size"],[611,62,595,29],[611,64,595,31,"datasets"],[611,72,595,39],[611,73,595,40,"i"],[611,74,595,41],[611,75,595,42],[611,76,595,43,"size"],[611,80,595,47],[611,81,595,48],[612,6,596,8],[613,4,597,4],[613,5,597,5],[613,11,598,9],[613,15,598,13,"datasets"],[613,23,598,21],[613,35,598,33,"Object"],[613,41,598,39],[613,43,598,41],[614,6,599,8],[614,11,599,13],[614,17,599,19,"ds"],[614,19,599,21],[614,23,599,25,"datasets"],[614,31,599,33],[614,33,599,35],[615,8,600,12,"size"],[615,12,600,16],[615,15,600,19,"size"],[615,19,600,23],[615,23,600,27],[615,27,600,31],[615,30,600,34,"datasets"],[615,38,600,42],[615,39,600,43,"ds"],[615,41,600,45],[615,42,600,46],[615,43,600,47,"size"],[615,47,600,51],[615,50,601,16,"Math"],[615,54,601,20],[615,55,601,21,"min"],[615,58,601,24],[615,59,601,25,"size"],[615,63,601,29],[615,65,601,31,"datasets"],[615,73,601,39],[615,74,601,40,"ds"],[615,76,601,42],[615,77,601,43],[615,78,601,44,"size"],[615,82,601,48],[615,83,601,49],[616,6,602,8],[617,4,603,4],[618,4,604,4],[618,11,604,11,"datasetFromIteratorFn"],[618,32,604,32],[618,33,604,33],[618,45,604,45],[619,6,605,8],[619,12,605,14,"streams"],[619,19,605,21],[619,22,605,24],[619,28,605,30],[619,32,605,30,"deepMapAndAwaitAll"],[619,45,605,48],[619,46,605,48,"deepMapAndAwaitAll"],[619,64,605,48],[619,66,605,49,"datasets"],[619,74,605,57],[619,76,605,59,"d"],[619,77,605,60],[619,81,605,64],[620,8,606,12],[620,12,606,16,"d"],[620,13,606,17],[620,25,606,29,"Dataset"],[620,32,606,36],[620,34,606,38],[621,10,607,16],[621,17,607,23],[622,12,607,25,"value"],[622,17,607,30],[622,19,607,32,"d"],[622,20,607,33],[622,21,607,34,"iterator"],[622,29,607,42],[622,30,607,43],[622,31,607,44],[623,12,607,46,"recurse"],[623,19,607,53],[623,21,607,55],[624,10,607,61],[624,11,607,62],[625,8,608,12],[625,9,608,13],[625,15,609,17],[625,19,609,21],[625,23,609,21,"isIterable"],[625,36,609,31],[625,37,609,31,"isIterable"],[625,47,609,31],[625,49,609,32,"d"],[625,50,609,33],[625,51,609,34],[625,53,609,36],[626,10,610,16],[626,17,610,23],[627,12,610,25,"value"],[627,17,610,30],[627,19,610,32],[627,23,610,36],[628,12,610,38,"recurse"],[628,19,610,45],[628,21,610,47],[629,10,610,52],[629,11,610,53],[630,8,611,12],[630,9,611,13],[630,15,612,17],[631,10,613,16],[631,16,613,22],[631,20,613,26,"Error"],[631,25,613,31],[631,26,613,32],[631,86,613,92],[631,89,614,20],[631,106,614,37],[631,107,614,38],[632,8,615,12],[633,6,616,8],[633,7,616,9],[633,8,616,10],[634,6,617,8],[634,13,617,15],[634,17,617,15,"iteratorFromZipped"],[634,40,617,33],[634,41,617,33,"iteratorFromZipped"],[634,59,617,33],[634,61,617,34,"streams"],[634,68,617,41],[634,70,617,43,"ZipMismatchMode"],[634,93,617,58],[634,94,617,58,"ZipMismatchMode"],[634,109,617,58],[634,110,617,59,"SHORTEST"],[634,118,617,67],[634,119,617,68],[635,4,618,4],[635,5,618,5],[635,7,618,7,"size"],[635,11,618,11],[635,12,618,12],[636,2,619,0],[637,2,620,0],[638,0,621,0],[639,0,622,0],[640,0,623,0],[641,0,624,0],[642,0,625,0],[643,0,626,0],[644,2,627,0],[645,2,628,0],[645,11,628,9,"deepBatchConcat"],[645,26,628,24,"deepBatchConcat"],[645,27,628,25,"rows"],[645,31,628,29],[645,33,628,31],[646,4,629,4],[646,8,629,8,"rows"],[646,12,629,12],[646,17,629,17],[646,21,629,21],[646,23,629,23],[647,6,630,8],[647,13,630,15],[647,17,630,19],[648,4,631,4],[649,4,632,4],[650,4,633,4],[650,10,633,10,"exampleRow"],[650,20,633,20],[650,23,633,23,"rows"],[650,27,633,27],[650,28,633,28],[650,29,633,29],[650,30,633,30],[651,4,634,4],[651,8,634,8],[651,12,634,8,"canTensorify"],[651,25,634,20],[651,26,634,20,"canTensorify"],[651,38,634,20],[651,40,634,21,"exampleRow"],[651,50,634,31],[651,51,634,32],[651,53,634,34],[652,6,635,8],[653,6,636,8],[653,12,636,14,"value"],[653,17,636,19],[653,20,636,22,"batchConcat"],[653,31,636,33],[653,32,636,34,"rows"],[653,36,636,38],[653,37,636,39],[654,6,637,8],[654,13,637,15],[655,8,637,17,"value"],[655,13,637,22],[656,8,637,24,"recurse"],[656,15,637,31],[656,17,637,33],[657,6,637,39],[657,7,637,40],[658,4,638,4],[659,4,639,4],[660,4,640,4],[660,11,640,11],[661,6,640,13,"value"],[661,11,640,18],[661,13,640,20],[661,17,640,24],[662,6,640,26,"recurse"],[662,13,640,33],[662,15,640,35],[663,4,640,40],[663,5,640,41],[664,2,641,0],[665,2,642,0],[666,0,643,0],[667,0,644,0],[668,0,645,0],[669,2,646,0],[669,11,646,9,"batchConcat"],[669,22,646,20,"batchConcat"],[669,23,646,21,"arrays"],[669,29,646,27],[669,31,646,29],[670,4,647,4],[670,8,647,8,"arrays"],[670,14,647,14],[670,15,647,15,"length"],[670,21,647,21],[670,26,647,26],[670,27,647,27],[670,29,647,29],[671,6,648,8],[672,6,649,8],[672,12,649,14],[672,16,649,18,"Error"],[672,21,649,23],[672,22,649,24],[672,61,649,63],[672,62,649,64],[673,4,650,4],[674,4,651,4],[674,8,651,8,"arrays"],[674,14,651,14],[674,15,651,15],[674,16,651,16],[674,17,651,17],[674,29,651,29,"tf"],[674,31,651,31],[674,32,651,32,"Tensor"],[674,38,651,38],[674,40,651,40],[675,6,652,8],[676,6,653,8],[676,13,653,15,"tf"],[676,15,653,17],[676,16,653,18,"stack"],[676,21,653,23],[676,22,653,24,"arrays"],[676,28,653,30],[676,29,653,31],[677,4,654,4],[677,5,654,5],[677,11,655,9],[678,6,656,8],[679,6,657,8],[679,13,657,15,"tf"],[679,15,657,17],[679,16,657,18,"tensor"],[679,22,657,24],[679,23,657,25,"arrays"],[679,29,657,31],[679,30,657,32],[680,4,658,4],[681,2,659,0],[682,0,659,1],[682,3]],"functionMap":{"names":["<global>","Dataset","Dataset#constructor","Dataset#batch","tf.util.assert$argument_1","datasetFromIteratorFn$argument_0","Dataset#concatenate","Dataset#filter","filter$argument_0","tf.tidy$argument_0","Dataset#forEachAsync","Dataset#map","map$argument_0","Dataset#mapAsync","Dataset#prefetch","Dataset#repeat","iteratorFromFunction$argument_0","Dataset#skip","Dataset#shuffle","Dataset#take","Dataset#toArray","Dataset#toArrayForTest","datasetFromIteratorFn","<anonymous>","constructor","iterator","array","zip","deepMapAndAwaitAll$argument_1","deepBatchConcat","batchConcat"],"mappings":"AAA;ACkD;ICC;KDE;IE6D;sCCE;mBDC;qCEiB;SFG;KFC;IKgB;qCDkB,yEC;KLC;IMiB;qCFY;kDGC,aC,kBD,CH;SEC;KNC;ISiB;KTE;IUgB;qCNE;+COC,aH,kBG,CP;SMC;KVC;IYwB;qCRE;SQE;KZC;IaU;qCTK,wDS;KbC;IcmB;qCVsB;0DWC,2DX;SUE;KdC;IgBkB;qCZmB,+CY;KhBC;IiBsB;qCbc;SaM;KjBC;IkBkB;qCdiB,+Cc;KlBC;ImBiB;KnBK;IoBY;KpBK;CDC;OsBgB;eCC;QCC;SDG;QEK;SFE;KDC;CtBC;O0BmB;iCrBC,oCqB;C1BC;O2B0C;iCtBkB;2DuBC;SvBW;KsBE;C3BC;A6BS;C7Ba;A8BK;C9Ba"},"hasCjsExports":false},"type":"js/module"}]}