{"dependencies":[{"name":"../tensor_util_env","data":{"asyncType":null,"isESMImport":true,"locs":[{"start":{"line":17,"column":0,"index":703},"end":{"line":17,"column":48,"index":751}}],"key":"UCKDOr/oOGi3nbD26ZhyAVW61qk=","exportNames":["*"],"imports":1}},{"name":"./tensor_ops_util","data":{"asyncType":null,"isESMImport":true,"locs":[{"start":{"line":18,"column":0,"index":752},"end":{"line":18,"column":47,"index":799}}],"key":"f+oyMOPjf4PZCeKJjBzeXW8Y0ek=","exportNames":["*"],"imports":1}}],"output":[{"data":{"code":"__d(function (global, require, _$$_IMPORT_DEFAULT, _$$_IMPORT_ALL, module, exports, _dependencyMap) {\n  \"use strict\";\n\n  Object.defineProperty(exports, '__esModule', {\n    value: true\n  });\n  exports.tensor = tensor;\n  var _tensor_util_env = require(_dependencyMap[0], \"../tensor_util_env\");\n  var _tensor_ops_util = require(_dependencyMap[1], \"./tensor_ops_util\");\n  /**\n   * @license\n   * Copyright 2018 Google LLC. All Rights Reserved.\n   * Licensed under the Apache License, Version 2.0 (the \"License\");\n   * you may not use this file except in compliance with the License.\n   * You may obtain a copy of the License at\n   *\n   * http://www.apache.org/licenses/LICENSE-2.0\n   *\n   * Unless required by applicable law or agreed to in writing, software\n   * distributed under the License is distributed on an \"AS IS\" BASIS,\n   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   * See the License for the specific language governing permissions and\n   * limitations under the License.\n   * =============================================================================\n   */\n\n  /**\n   * Creates a `tf.Tensor` with the provided values, shape and dtype.\n   *\n   * ```js\n   * // Pass an array of values to create a vector.\n   * tf.tensor([1, 2, 3, 4]).print();\n   * ```\n   *\n   * ```js\n   * // Pass a nested array of values to make a matrix or a higher\n   * // dimensional tensor.\n   * tf.tensor([[1, 2], [3, 4]]).print();\n   * ```\n   *\n   * ```js\n   * // Pass a flat array and specify a shape yourself.\n   * tf.tensor([1, 2, 3, 4], [2, 2]).print();\n   * ```\n   *\n   * ```js\n   * // Pass a `WebGLData` object and specify a shape yourself.\n   *\n   * // This makes it possible for TF.js applications to avoid GPU / CPU sync.\n   * // For example, if your application includes a preprocessing step on the GPU,\n   * // you could upload the GPU output directly to TF.js, rather than first\n   * // downloading the values.\n   *\n   * // Example for WebGL2:\n   * if (tf.findBackend('custom-webgl') == null) {\n   *   const customCanvas = document.createElement('canvas');\n   *   const customBackend = new tf.MathBackendWebGL(customCanvas);\n   *   tf.registerBackend('custom-webgl', () => customBackend);\n   * }\n   * const savedBackend = tf.getBackend();\n   * await tf.setBackend('custom-webgl');\n   * const gl = tf.backend().gpgpu.gl;\n   * const texture = gl.createTexture();\n   * const tex2d = gl.TEXTURE_2D;\n   * const width = 2;\n   * const height = 2;\n   *\n   * gl.bindTexture(tex2d, texture);\n   * gl.texParameteri(tex2d, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n   * gl.texParameteri(tex2d, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n   * gl.texParameteri(tex2d, gl.TEXTURE_MIN_FILTER, gl.NEAREST);\n   * gl.texParameteri(tex2d, gl.TEXTURE_MAG_FILTER, gl.NEAREST);\n   * gl.texImage2D(\n   *   tex2d, 0, gl.RGBA32F, // internalFormat\n   *   width, height, 0,\n   *   gl.RGBA, // textureFormat\n   *   gl.FLOAT, // textureType\n   *   new Float32Array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n   * );\n   *\n   * // Currently, the `texture` has 4 pixels:\n   * // Pixel0 is {R:0, G:1, B:2, A:3}\n   * // Pixel1 is {R:4, G:5, B:6, A:7}\n   * // Pixel2 is {R:8, G:9, B:10, A:11}\n   * // Pixel3 is {R:12, G:13, B:14, A:15}\n   *\n   * const logicalShape = [height * width * 2];\n   * const a = tf.tensor({texture, height, width, channels: 'BR'}, logicalShape);\n   * a.print();\n   * // Tensor value will be [2, 0, 6, 4, 10, 8, 14, 12], since [2, 0] is the\n   * // values of 'B' and 'R' channels of Pixel0, [6, 4] is the values of 'B' and\n   * 'R'\n   * // channels of Pixel1...\n   *\n   * // For postprocessing on the GPU, it's possible to retrieve the texture\n   * // backing any tensor by calling the tensor's `dataToGPU` method like\n   * // so:\n   *\n   * const tex = a.dataToGPU();\n   * await tf.setBackend(savedBackend);\n   * ```\n   *\n   * ```js\n   * // Pass a `WebGPUData` object and specify a shape yourself.\n   *\n   * // This makes it possible for TF.js applications to avoid GPU / CPU sync.\n   * // For example, if your application includes a preprocessing step on the GPU,\n   * // you could upload the GPU output directly to TF.js, rather than first\n   * // downloading the values. Unlike WebGL, this optionally supports zero copy\n   * // by WebGPUData.zeroCopy. When zeroCopy is false or undefined(default), this\n   * // passing GPUBuffer can be destroyed after tensor is created. When zeroCopy\n   * // is true, this GPUBuffer is bound directly by the tensor, so do not destroy\n   * // this GPUBuffer until all access is done.\n   *\n   * // Example for WebGPU:\n   * function createGPUBufferFromData(device, data, dtype) {\n   *   const bytesPerElement = 4;\n   *   const sizeInBytes = data.length * bytesPerElement;\n   *\n   *   const gpuWriteBuffer = device.createBuffer({\n   *     mappedAtCreation: true,\n   *     size: sizeInBytes,\n   *     usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC\n   *   });\n   *   const arrayBuffer = gpuWriteBuffer.getMappedRange();\n   *   if (dtype === 'float32') {\n   *     new Float32Array(arrayBuffer).set(data);\n   *   } else if (dtype === 'int32') {\n   *     new Int32Array(arrayBuffer).set(data);\n   *   } else {\n   *     throw new Error(\n   *         `Creating tensor from GPUBuffer only supports` +\n   *         `'float32'|'int32' dtype, while the dtype is ${dtype}.`);\n   *   }\n   *   gpuWriteBuffer.unmap();\n   *\n   *   const gpuReadBuffer = device.createBuffer({\n   *     mappedAtCreation: false,\n   *     size: sizeInBytes,\n   *     usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.STORAGE |\n   *         GPUBufferUsage.COPY_SRC\n   *   });\n   *\n   *   const copyEncoder = device.createCommandEncoder();\n   *   copyEncoder.copyBufferToBuffer(\n   *       gpuWriteBuffer, 0, gpuReadBuffer, 0, sizeInBytes);\n   *   const copyCommands = copyEncoder.finish();\n   *   device.queue.submit([copyCommands]);\n   *   gpuWriteBuffer.destroy();\n   *   return gpuReadBuffer;\n   * }\n   *\n   * const savedBackend = tf.getBackend();\n   * await tf.setBackend('webgpu').catch(\n   *     () => {throw new Error(\n   *         'Failed to use WebGPU backend. Please use Chrome Canary to run.')});\n   * const dtype = 'float32';\n   * const device = tf.backend().device;\n   * const aData = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16];\n   * const bData = [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4];\n   * const expected = [2, 4, 6, 8, 6, 8, 10, 12, 10, 12, 14, 16, 14, 16, 18, 20];\n   * const aBuffer = createGPUBufferFromData(device, aData, dtype);\n   * const shape = [aData.length];\n   * // To use zeroCopy, use {buffer: aBuffer, zeroCopy: true} instead and destroy\n   * // aBuffer untill all access is done.\n   * const a = tf.tensor({buffer: aBuffer}, shape, dtype);\n   * const b = tf.tensor(bData, shape, dtype);\n   * const result = tf.add(a, b);\n   * result.print();\n   * a.dispose();\n   * b.dispose();\n   * result.dispose();\n   * aBuffer.destroy();\n   * await tf.setBackend(savedBackend);\n   * ```\n   * @param values The values of the tensor. Can be nested array of numbers,\n   * or a flat array, or a `TypedArray`(At the moment it supports Uint8Array,\n   * Uint8ClampedArray, Int32Array, Float32Array) data types, or a `WebGLData`\n   * object, or a `WebGPUData` object. If the values are strings, they will be\n   * encoded as utf-8 and kept as `Uint8Array[]`. If the values is a `WebGLData`\n   * object, the dtype could only be 'float32' or 'int32' and the object has to\n   * have: 1. texture, a `WebGLTexture`, the texture must share the same\n   * `WebGLRenderingContext` with TFJS's WebGL backend (you could create a custom\n   * WebGL backend from your texture's canvas) and the internal texture format\n   * for the input texture must be floating point or normalized integer; 2.\n   * height, the height of the texture; 3. width, the width of the texture; 4.\n   * channels, a non-empty subset of 'RGBA', indicating the values of which\n   * channels will be passed to the tensor, such as 'R' or 'BR' (The order of the\n   * channels affect the order of tensor values. ). (If the values passed from\n   * texture is less than the tensor size, zeros will be padded at the rear.). If\n   * the values is a `WebGPUData` object, the dtype could only be 'float32' or\n   * 'int32 and the object has to have: buffer, a `GPUBuffer`. The buffer must:\n   * 1. share the same `GPUDevice` with TFJS's WebGPU backend; 2. buffer.usage\n   * should at least support GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC; 3.\n   * buffer.size should not be smaller than the byte size of tensor shape.\n   * WebGPUData optionally supports zero copy by flag zeroCopy. When zeroCopy is\n   * false or undefined(default),this passing GPUBuffer can be destroyed after\n   * tensor is created. When zeroCopy is true, this GPUBuffer is bound directly\n   * by the tensor, so do not destroy this GPUBuffer until all access is done.\n   * @param shape The shape of the tensor. Optional. If not provided,\n   *   it is inferred from `values`.\n   * @param dtype The data type.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n  function tensor(values, shape, dtype) {\n    const inferredShape = (0, _tensor_util_env.inferShape)(values, dtype);\n    return (0, _tensor_ops_util.makeTensor)(values, shape, inferredShape, dtype);\n  }\n});","lineCount":210,"map":[[7,2,198,0,"exports"],[7,9,198,0],[7,10,198,0,"tensor"],[7,16,198,0],[7,19,198,0,"tensor"],[7,25,198,0],[8,2,17,0],[8,6,17,0,"_tensor_util_env"],[8,22,17,0],[8,25,17,0,"require"],[8,32,17,0],[8,33,17,0,"_dependencyMap"],[8,47,17,0],[9,2,18,0],[9,6,18,0,"_tensor_ops_util"],[9,22,18,0],[9,25,18,0,"require"],[9,32,18,0],[9,33,18,0,"_dependencyMap"],[9,47,18,0],[10,2,1,0],[11,0,2,0],[12,0,3,0],[13,0,4,0],[14,0,5,0],[15,0,6,0],[16,0,7,0],[17,0,8,0],[18,0,9,0],[19,0,10,0],[20,0,11,0],[21,0,12,0],[22,0,13,0],[23,0,14,0],[24,0,15,0],[25,0,16,0],[27,2,19,0],[28,0,20,0],[29,0,21,0],[30,0,22,0],[31,0,23,0],[32,0,24,0],[33,0,25,0],[34,0,26,0],[35,0,27,0],[36,0,28,0],[37,0,29,0],[38,0,30,0],[39,0,31,0],[40,0,32,0],[41,0,33,0],[42,0,34,0],[43,0,35,0],[44,0,36,0],[45,0,37,0],[46,0,38,0],[47,0,39,0],[48,0,40,0],[49,0,41,0],[50,0,42,0],[51,0,43,0],[52,0,44,0],[53,0,45,0],[54,0,46,0],[55,0,47,0],[56,0,48,0],[57,0,49,0],[58,0,50,0],[59,0,51,0],[60,0,52,0],[61,0,53,0],[62,0,54,0],[63,0,55,0],[64,0,56,0],[65,0,57,0],[66,0,58,0],[67,0,59,0],[68,0,60,0],[69,0,61,0],[70,0,62,0],[71,0,63,0],[72,0,64,0],[73,0,65,0],[74,0,66,0],[75,0,67,0],[76,0,68,0],[77,0,69,0],[78,0,70,0],[79,0,71,0],[80,0,72,0],[81,0,73,0],[82,0,74,0],[83,0,75,0],[84,0,76,0],[85,0,77,0],[86,0,78,0],[87,0,79,0],[88,0,80,0],[89,0,81,0],[90,0,82,0],[91,0,83,0],[92,0,84,0],[93,0,85,0],[94,0,86,0],[95,0,87,0],[96,0,88,0],[97,0,89,0],[98,0,90,0],[99,0,91,0],[100,0,92,0],[101,0,93,0],[102,0,94,0],[103,0,95,0],[104,0,96,0],[105,0,97,0],[106,0,98,0],[107,0,99,0],[108,0,100,0],[109,0,101,0],[110,0,102,0],[111,0,103,0],[112,0,104,0],[113,0,105,0],[114,0,106,0],[115,0,107,0],[116,0,108,0],[117,0,109,0],[118,0,110,0],[119,0,111,0],[120,0,112,0],[121,0,113,0],[122,0,114,0],[123,0,115,0],[124,0,116,0],[125,0,117,0],[126,0,118,0],[127,0,119,0],[128,0,120,0],[129,0,121,0],[130,0,122,0],[131,0,123,0],[132,0,124,0],[133,0,125,0],[134,0,126,0],[135,0,127,0],[136,0,128,0],[137,0,129,0],[138,0,130,0],[139,0,131,0],[140,0,132,0],[141,0,133,0],[142,0,134,0],[143,0,135,0],[144,0,136,0],[145,0,137,0],[146,0,138,0],[147,0,139,0],[148,0,140,0],[149,0,141,0],[150,0,142,0],[151,0,143,0],[152,0,144,0],[153,0,145,0],[154,0,146,0],[155,0,147,0],[156,0,148,0],[157,0,149,0],[158,0,150,0],[159,0,151,0],[160,0,152,0],[161,0,153,0],[162,0,154,0],[163,0,155,0],[164,0,156,0],[165,0,157,0],[166,0,158,0],[167,0,159,0],[168,0,160,0],[169,0,161,0],[170,0,162,0],[171,0,163,0],[172,0,164,0],[173,0,165,0],[174,0,166,0],[175,0,167,0],[176,0,168,0],[177,0,169,0],[178,0,170,0],[179,0,171,0],[180,0,172,0],[181,0,173,0],[182,0,174,0],[183,0,175,0],[184,0,176,0],[185,0,177,0],[186,0,178,0],[187,0,179,0],[188,0,180,0],[189,0,181,0],[190,0,182,0],[191,0,183,0],[192,0,184,0],[193,0,185,0],[194,0,186,0],[195,0,187,0],[196,0,188,0],[197,0,189,0],[198,0,190,0],[199,0,191,0],[200,0,192,0],[201,0,193,0],[202,0,194,0],[203,0,195,0],[204,0,196,0],[205,0,197,0],[206,2,198,7],[206,11,198,16,"tensor"],[206,17,198,22,"tensor"],[206,18,198,23,"values"],[206,24,198,29],[206,26,198,31,"shape"],[206,31,198,36],[206,33,198,38,"dtype"],[206,38,198,43],[206,40,198,45],[207,4,199,4],[207,10,199,10,"inferredShape"],[207,23,199,23],[207,26,199,26],[207,30,199,26,"inferShape"],[207,46,199,36],[207,47,199,36,"inferShape"],[207,57,199,36],[207,59,199,37,"values"],[207,65,199,43],[207,67,199,45,"dtype"],[207,72,199,50],[207,73,199,51],[208,4,200,4],[208,11,200,11],[208,15,200,11,"makeTensor"],[208,31,200,21],[208,32,200,21,"makeTensor"],[208,42,200,21],[208,44,200,22,"values"],[208,50,200,28],[208,52,200,30,"shape"],[208,57,200,35],[208,59,200,37,"inferredShape"],[208,72,200,50],[208,74,200,52,"dtype"],[208,79,200,57],[208,80,200,58],[209,2,201,0],[210,0,201,1],[210,3]],"functionMap":{"names":["<global>","tensor"],"mappings":"AAA;OCqM;CDG"},"hasCjsExports":false},"type":"js/module"}]}